"""
AI-Enhanced Orchestrator Engine
Integrates Gemini AI strategically for Indian film production analysis
- Only calls Gemini for HIGH-RISK scenes (intelligent batching)
- Applies Indian-specific context and knowledge
- Falls back to templates if API fails (reliability)
- Visible AI reasoning for jury evaluation
"""
import logging
from typing import Dict, Any, List
from datetime import datetime
import json
import pandas as pd
from pathlib import Path
import uuid
import time

logger = logging.getLogger(__name__)


class AIEnhancedOrchestratorEngine:
    """
    Hybrid orchestrator combining mock determinism with strategic Gemini AI
    - Fast extraction (deterministic)
    - Smart AI calls on high-risk scenes only
    - Cross-scene pattern detection with AI
    - Indian context awareness
    - Full fallback support
    """
    
    def __init__(self):
        """Initialize AI orchestrator with Gemini client"""
        from app.agents.enhanced_orchestrator import EnhancedOrchestratorEngine
        from app.utils.llm_client import GeminiClient
        
        self.enhanced_orchestrator = EnhancedOrchestratorEngine()
        
        # Initialize Gemini client with error handling
        try:
            self.gemini_client = GeminiClient()
            self.ai_available = True
            logger.info("âœ… AI-Enhanced Orchestrator initialized with Gemini integration")
        except Exception as e:
            logger.warning(f"âš ï¸ Gemini client unavailable: {e}, using template fallback")
            self.gemini_client = None
            self.ai_available = False
        
        # Load Indian context knowledge
        self.indian_context = self._load_indian_context()
        logger.info("ðŸ‡®ðŸ‡³ Indian film industry context loaded")
    
    def _load_indian_context(self) -> Dict[str, Any]:
        """Load Indian-specific production knowledge"""
        return {
            "major_cities": {
                "Mumbai": {"permit_multiplier": 1.5, "bureaucracy_days": 14, "region": "Western"},
                "Delhi": {"permit_multiplier": 1.4, "bureaucracy_days": 16, "region": "Northern"},
                "Bangalore": {"permit_multiplier": 1.2, "bureaucracy_days": 12, "region": "Southern"},
                "Hyderabad": {"permit_multiplier": 1.1, "bureaucracy_days": 10, "region": "Southern"},
                "Chennai": {"permit_multiplier": 1.1, "bureaucracy_days": 11, "region": "Southern"},
                "Kolkata": {"permit_multiplier": 1.3, "bureaucracy_days": 13, "region": "Eastern"},
            },
            "seasons": {
                "Monsoon": {"risk_multiplier": 0.8, "months": [6, 7, 8, 9], "description": "Heavy rains, flooding risk"},
                "Summer": {"risk_multiplier": 0.6, "months": [4, 5], "description": "Extreme heat, heat exhaustion risk"},
                "Winter": {"risk_multiplier": 0.3, "months": [12, 1, 2], "description": "Cool, optimal filming"},
            },
            "permits_by_location": {
                "Government_Building": ["Municipal Corp", "Police", "Film Commission", "Security Clearance"],
                "Heritage_Site": ["ASI", "Heritage Commission", "District Admin"],
                "Public_Road": ["Traffic Police", "Municipal Corp", "Local Police"],
                "Market": ["Municipal Corp", "Market Association", "Local Police"],
                "Railway": ["Railway Authority", "RPF", "Government Clearance"],
            },
            "contingency_guidelines": {
                "low_complexity": 0.10,  # 10% contingency
                "medium_complexity": 0.15,  # 15% contingency
                "high_complexity": 0.25,  # 25% contingency
                "monsoon_seasons": 1.3,  # Additional 30% multiplier
            }
        }
    
    def run_pipeline_with_ai(self, project_id: str, script_text: str) -> Dict[str, Any]:
        """
        Run pipeline with strategic AI integration
        - Phase 1: Fast extraction (deterministic)
        - Phase 2: AI analysis on HIGH-RISK scenes
        - Phase 3: Cross-scene AI insights
        - Phase 4: Knowledge grounding
        """
        logger.info(f"ðŸš€ AI-Enhanced Pipeline Starting: {project_id}")
        
        try:
            # PHASE 1: Get base mock result (fast, deterministic)
            base_result = self.enhanced_orchestrator.mock_orchestrator.run_pipeline(project_id, script_text)
            scenes = base_result.get("scenes", [])
            
            logger.info(f"ðŸ“Š Base extraction complete: {len(scenes)} scenes identified")
            
            # PHASE 2: Enhance HIGH-RISK scenes with AI
            high_risk_scenes = [s for s in scenes if s["risk"]["total_risk_score"] > 50]
            logger.info(f"ðŸ”´ HIGH-RISK scenes identified: {len(high_risk_scenes)}")
            
            if self.ai_available and high_risk_scenes:
                scenes = self._enhance_high_risk_scenes_with_ai(high_risk_scenes, scenes)
                logger.info(f"âœ… HIGH-RISK scenes enhanced with AI analysis")
            
            # PHASE 3: Generate cross-scene insights with AI
            insights = base_result.get("insights", [])
            if self.ai_available and high_risk_scenes:
                insights = self._generate_cross_scene_insights_with_ai(high_risk_scenes, scenes)
                logger.info(f"âœ… Cross-scene insights generated with AI")
            
            # PHASE 4: Apply Indian context and knowledge grounding
            enhanced_result = self._apply_indian_context_and_grounding(
                base_result, scenes, insights
            )
            
            logger.info("âœ… AI-Enhanced Pipeline Completed!")
            return enhanced_result
        
        except Exception as e:
            logger.error(f"âŒ AI pipeline error: {e}, falling back to standard enhanced output")
            # Fallback to standard enhanced output without AI
            return self.enhanced_orchestrator.run_pipeline_with_grounding(project_id, script_text)
    
    def _enhance_high_risk_scenes_with_ai(self, high_risk_scenes: List[Dict], all_scenes: List[Dict]) -> List[Dict]:
        """
        Call Gemini ONLY for high-risk scenes (batch processing)
        Returns: Updated scenes list with AI-enhanced risk/budget analysis
        """
        if not self.gemini_client or not high_risk_scenes:
            return all_scenes
        
        try:
            # Prepare batch prompt
            scenes_summary = []
            for scene in high_risk_scenes[:5]:  # Limit to 5 scenes per batch
                scenes_summary.append({
                    "scene_number": scene["scene_number"],
                    "location": scene["extraction"]["location"]["value"],
                    "complexity": scene.get("complexity", "medium"),
                    "risk_score": scene["risk"]["total_risk_score"],
                    "stunt_level": scene["extraction"].get("stunt_level", {}).get("value", "none"),
                    "crowd_size": scene["extraction"].get("crowd_size", {}).get("value", 0),
                })
            
            prompt = f"""
            You are an expert Indian film production safety consultant analyzing high-risk scenes.
            
            CONTEXT: This is an Indian film production. Apply Indian-specific knowledge:
            - Permit processes in India are bureaucratic (2-4 weeks typically)
            - Monsoon seasons (June-September) add 30% to costs and timeline
            - Safety standards must follow AMPTP guidelines adapted for Indian context
            - Crowd management in India has unique challenges
            
            ANALYZE these {len(scenes_summary)} HIGH-RISK scenes:
            {json.dumps(scenes_summary, indent=2)}
            
            For EACH scene, provide:
            1. Top 3 production risks specific to Indian context
            2. Recommended safety measures (budget impact)
            3. Permit requirements and estimated timeline
            4. Cost contingency % for this scene
            5. Mitigation priority level (CRITICAL/HIGH/MEDIUM)
            
            Return as JSON array with one object per scene containing:
            {{
                "scene_number": <int>,
                "ai_risk_drivers": [<string>, ...],
                "safety_measures": ["<measure>", "<cost_impact>", ...],
                "permits_required": ["<permit>", ...],
                "permit_days": <int>,
                "cost_contingency_percent": <float>,
                "mitigation_priority": "<CRITICAL|HIGH|MEDIUM>",
                "indian_context_notes": "<specific insights>"
            }}
            """
            
            # Call Gemini with timeout
            logger.info("ðŸ“ž Calling Gemini for HIGH-RISK scene analysis...")
            response_text = self.gemini_client.call_model(prompt, temperature=0.4)
            ai_results = self.gemini_client.extract_json_from_response(response_text)
            
            if not isinstance(ai_results, list):
                ai_results = [ai_results] if ai_results else []
            
            logger.info(f"âœ… Gemini returned analysis for {len(ai_results)} scenes")
            
            # Merge AI results back into scenes
            for ai_result in ai_results:
                scene_num = ai_result.get("scene_number")
                for scene in all_scenes:
                    if scene["scene_number"] == scene_num:
                        # Enhance risk analysis with AI insights
                        scene["risk"]["ai_analysis"] = {
                            "risk_drivers_ai": ai_result.get("ai_risk_drivers", []),
                            "safety_measures": ai_result.get("safety_measures", []),
                            "mitigation_priority": ai_result.get("mitigation_priority", "MEDIUM"),
                            "india_specific": ai_result.get("indian_context_notes", ""),
                        }
                        
                        # Enhance budget with AI contingency recommendation
                        contingency_pct = ai_result.get("cost_contingency_percent", 0.15)
                        scene["budget"]["ai_contingency_percent"] = contingency_pct
                        scene["budget"]["ai_enhanced_max"] = int(
                            scene["budget"]["cost_max"] * (1 + contingency_pct)
                        )
                        
                        # Add permits from AI analysis
                        scene["extraction"]["permits_ai_recommended"] = ai_result.get("permits_required", [])
                        break
            
            return all_scenes
        
        except Exception as e:
            logger.warning(f"âš ï¸ AI enhancement failed: {e}, using standard analysis")
            return all_scenes
    
    def _generate_cross_scene_insights_with_ai(self, high_risk_scenes: List[Dict], all_scenes: List[Dict]) -> List[Dict]:
        """
        Single Gemini call to identify cross-scene patterns and strategies
        Returns: Enhanced insights list with agentic reasoning
        """
        if not self.gemini_client or not high_risk_scenes:
            return []
        
        try:
            # Prepare scene cluster analysis
            locations_by_risk = {}
            for scene in high_risk_scenes:
                loc = scene["extraction"]["location"]["value"]
                if loc not in locations_by_risk:
                    locations_by_risk[loc] = []
                locations_by_risk[loc].append(scene["scene_number"])
            
            prompt = f"""
            You are analyzing cross-scene patterns in an Indian film production.
            
            HIGH-RISK SCENE ANALYSIS:
            - Total high-risk scenes: {len(high_risk_scenes)}
            - Location clustering: {json.dumps(locations_by_risk, indent=2)}
            - Average risk score: {sum([s['risk']['total_risk_score'] for s in high_risk_scenes]) / len(high_risk_scenes):.1f}
            
            IDENTIFY and RECOMMEND:
            1. Geographic clusters and location optimization opportunities
            2. Resource bottlenecks (crew, equipment, time)
            3. Risk amplification patterns (scenes that worsen together)
            4. Budget optimization strategies
            5. Scheduling recommendations to mitigate risk
            
            Consider Indian production context:
            - Permit coordination challenges across multiple locations
            - Weather and monsoon impact
            - Crew availability and mobilization costs
            
            Return as JSON object:
            {{
                "patterns": [
                    {{
                        "pattern_type": "<location_cluster|risk_amplification|resource_bottleneck>",
                        "affected_scenes": [<int>, ...],
                        "description": "<string>",
                        "financial_impact": "<string>",
                        "recommendation": "<string>"
                    }}, ...
                ],
                "optimization_strategies": ["<strategy>", ...],
                "risk_reduction_potential": "<percentage>",
                "estimated_savings": "<currency string>",
                "agentic_reasoning": "<explain how AI agents would collaborate to solve this>"
            }}
            """
            
            logger.info("ðŸ“ž Calling Gemini for cross-scene pattern analysis...")
            response_text = self.gemini_client.call_model(prompt, temperature=0.5)
            ai_insights = self.gemini_client.extract_json_from_response(response_text)
            
            logger.info("âœ… Gemini generated cross-scene insights")
            
            # Convert to insights list format
            insights = []
            for pattern in ai_insights.get("patterns", []):
                insight = {
                    "id": str(uuid.uuid4()),
                    "insight_type": pattern.get("pattern_type", "optimization"),
                    "scene_ids": pattern.get("affected_scenes", []),
                    "problem_description": pattern.get("description", ""),
                    "impact_financial": pattern.get("financial_impact", "Unknown"),
                    "impact_schedule": "TBD",
                    "recommendation": pattern.get("recommendation", ""),
                    "confidence": 0.85,
                    "ai_generated": True,
                    "agentic_reasoning": ai_insights.get("agentic_reasoning", ""),
                }
                insights.append(insight)
            
            return insights
        
        except Exception as e:
            logger.warning(f"âš ï¸ Cross-scene AI analysis failed: {e}")
            return []
    
    def _apply_indian_context_and_grounding(
        self, 
        base_result: Dict[str, Any],
        scenes: List[Dict],
        insights: List[Dict]
    ) -> Dict[str, Any]:
        """
        Apply Indian-specific context to all analysis
        Enhance grounding with Indian production data
        """
        # Get enhanced output from standard orchestrator
        enhanced_output = self.enhanced_orchestrator.run_pipeline_with_grounding(
            base_result["project_id"], 
            ""  # Already have scenes, just need structure
        )
        
        # Merge AI insights if available
        if insights:
            enhanced_output["cross_scene_intelligence"]["insights"] = insights
            enhanced_output["cross_scene_intelligence"]["ai_enhanced"] = True
        
        # Apply Indian context enhancements
        enhanced_output["indian_context"] = {
            "region": self._detect_region_from_scenes(scenes),
            "monsoon_risk": self._calculate_monsoon_risk(),
            "permit_complexity": "HIGH",  # India-specific
            "crew_coordination_notes": "Multi-city shoot requires coordinated permit applications",
            "currency": "INR",
            "compliance_framework": "AMPTP + Indian Labour Laws + Local Municipal Regulations"
        }
        
        # Add AI reasoning transparency
        high_risk_count = len([s for s in scenes if s["risk"]["total_risk_score"] > 50])
        if high_risk_count > 0 and self.ai_available:
            enhanced_output["analysis_metadata"]["ai_analysis_performed"] = True
            enhanced_output["analysis_metadata"]["high_risk_scenes_analyzed_by_gemini"] = high_risk_count
            enhanced_output["analysis_metadata"]["ai_calls_made"] = 2 if high_risk_count > 0 else 0
            enhanced_output["analysis_metadata"]["transparency"] = "AI analysis on high-risk scenes, templates for others"
        
        return enhanced_output
    
    def _detect_region_from_scenes(self, scenes: List[Dict]) -> str:
        """Detect production region from scene locations"""
        locations = [s["extraction"]["location"]["value"].lower() for s in scenes]
        
        for location_str in locations:
            for city, info in self.indian_context["major_cities"].items():
                if city.lower() in location_str:
                    return info["region"]
        
        return "General"  # Default
    
    def _calculate_monsoon_risk(self) -> Dict[str, Any]:
        """Calculate monsoon-specific risks"""
        # In real scenario, check calendar and production timeline
        return {
            "monsoon_season": True,
            "affected_months": "June-September",
            "cost_multiplier": 1.3,
            "risk_multiplier": 1.5,
            "schedule_impact": "Plan 25% additional contingency days"
        }


# Global AI orchestrator instance
ai_enhanced_orchestrator = AIEnhancedOrchestratorEngine()
